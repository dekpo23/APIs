{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8a8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "304b8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scores(\n",
    "        scores: List[int],\n",
    "        info: Dict[str, Union[int, float]],\n",
    "        comment: Optional[str] = None) -> None:\n",
    "    print('Scores:', scores)\n",
    "    print('info', info)\n",
    "    if comment:\n",
    "        print('Comment:', comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023a9404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [10, 20]\n",
      "info {'David': 'Ekpo', 'Divine': 'John', 'Blessing': 'John'}\n"
     ]
    }
   ],
   "source": [
    "process_scores([10, 20], {'David': 'Ekpo', 'Divine': 'John', 'Blessing': 'John'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e263bf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Toyeebat Arike\n",
      "Hello Toyeebat\n"
     ]
    }
   ],
   "source": [
    "def greet(first_name: str, last_name: Optional[str] = None)->  None:\n",
    "    if last_name:\n",
    "        print(f\"Hello {first_name} {last_name}\")\n",
    "    else:\n",
    "        print(f\"Hello {first_name}\")\n",
    "\n",
    "greet('Toyeebat', 'Arike')\n",
    "greet('Toyeebat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50e4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_user(username: str) -> Optional[dict]:\n",
    "    if username == 'admin':\n",
    "        return {'username': 'admin', 'role': 'superuser'}\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8239004b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'username': 'admin', 'role': 'superuser'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1 = find_user('admin')\n",
    "user1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d94ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydantic --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63456eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fellow(name='Perpetual', score=88, track='AI Engineering')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "class Fellow(BaseModel):\n",
    "    name: str\n",
    "    score: int\n",
    "    track: str\n",
    "\n",
    "Fellow(name='Perpetual', score=88, track = \"AI Engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb47fe47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Fellow\nscore\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='eigty-seven', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mFellow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mZach\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43meigty-seven\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAI Engineering\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user47\\Documents\\FastApi\\backend\\Lib\\site-packages\\pydantic\\main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Fellow\nscore\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='eigty-seven', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/int_parsing"
     ]
    }
   ],
   "source": [
    "Fellow(name = 'Zach', score = 'eigty-seven', track = 'AI Engineering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "672d442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Fellow(name = 'Perpetual', score = '88', track = 'AI Engineering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad14b12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(p.score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "338f2e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Blessing' score=100 track='AI Engineering'\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "data = {'name': 'Blessing', 'score': '100', 'track': 'AI Engineering'}\n",
    "\n",
    "fellow = Fellow(**data)\n",
    "\n",
    "print(fellow)\n",
    "print(type(fellow.score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dc9ecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":\"Perpetual\",\"score\":88,\"track\":\"AI Engineering\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user47\\AppData\\Local\\Temp\\ipykernel_4648\\2201927859.py:1: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
      "  print(p.json())\n"
     ]
    }
   ],
   "source": [
    "print(p.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "598f183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":\"Perpetual\",\"score\":88,\"track\":\"AI Engineering\"}\n"
     ]
    }
   ],
   "source": [
    "print(p.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9242aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    city: str\n",
    "    state: str\n",
    "    country: str\n",
    "\n",
    "class Fellow(BaseModel):\n",
    "    name: str\n",
    "    score: int\n",
    "    track: str\n",
    "    address: Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7891e437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Perpetual' score=88 track='AI Engineering' address=Address(street='Ajelogo Street', city='Ketu', state='Lagos', country='Nigeria')\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"name\": \"Perpetual\", \n",
    "    \"score\": 88,\n",
    "    \"track\": \"AI Engineering\",\n",
    "\n",
    "    \"address\": {\n",
    "        \"street\": \"Ajelogo Street\",\n",
    "        \"city\": \"Ketu\",\n",
    "        \"state\": \"Lagos\",\n",
    "        \"country\": \"Nigeria\"\n",
    "    }\n",
    "}\n",
    "\n",
    "fellow = Fellow(**data)\n",
    "print(fellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffe1649c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ajelogo Street'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fellow.address.street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65363ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Fellow(BaseModel):\n",
    "    name: str\n",
    "    score: int\n",
    "    track: str\n",
    "    addresses: List[Address]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65aac83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"name\": \"Perpetual\",\n",
    "    \"score\": 88,\n",
    "    \"track\": \"AI Engineering\",\n",
    "    \"addresses\": [\n",
    "        {\"street\": \"Idoroko Road\", \"city\": \"Sango\", \"state\": \"Ogun\",\n",
    "        \"country\": \"Nigeria\"},\n",
    "        {\"street\": \"Kobape\", \"city\": \"Abeokuta\", \"state\": \"Ogun\",\n",
    "        \"country\": \"Nigeria\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "fellow = Fellow(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "161f66af",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3538242750.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(fellow.addresses[1].city|)\u001b[39m\n                                   ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(fellow.addresses[0].city)\n",
    "print(fellow.addresses[1].city|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad179788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":\"Perpetual\",\"score\":88,\"track\":\"AI Engineering\",\"addresses\":[{\"street\":\"Idoroko Road\",\"city\":\"Sango\",\"state\":\"Ogun\",\"country\":\"Nigeria\"},{\"street\":\"Kobape\",\"city\":\"Abeokuta\",\"state\":\"Ogun\",\"country\":\"Nigeria\"}]}\n",
      "\n",
      "\n",
      "{'name': 'Perpetual', 'score': 88, 'track': 'AI Engineering', 'addresses': [{'street': 'Idoroko Road', 'city': 'Sango', 'state': 'Ogun', 'country': 'Nigeria'}, {'street': 'Kobape', 'city': 'Abeokuta', 'state': 'Ogun', 'country': 'Nigeria'}]}\n"
     ]
    }
   ],
   "source": [
    "print(fellow.model_dump_json())\n",
    "print(\"\\n\")\n",
    "print(fellow.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1aac6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Micheal' score=-79 addresses=[Address(street='123 Marose St', city='Ikorodu'), Address(street='4 Babatunde Ave', city='Abioloa Way')]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    city: str\n",
    "\n",
    "class Fellow(BaseModel):\n",
    "    name: str\n",
    "    score: int\n",
    "    addresses: List[Address]\n",
    "\n",
    "data = {\n",
    "    \"name\": \"Micheal\",\n",
    "    \"score\": -79,\n",
    "    \"addresses\": [\n",
    "        {\"street\": \"123 Marose St\", \"city\": \"Ikorodu\"},\n",
    "        {\"street\": \"4 Babatunde Ave\", \"city\": \"Abioloa Way\"}\n",
    "    ]\n",
    "}\n",
    "fellow = Fellow(**data)\n",
    "print(fellow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc7b06f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    city: str\n",
    "\n",
    "class Fellow(BaseModel):\n",
    "    name: str\n",
    "    score: int = Field(..., ge = 0, le=100)\n",
    "    addresses: List[Address]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f0ee04d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Fellow\nscore\n  Input should be greater than or equal to 0 [type=greater_than_equal, input_value=-40, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.12/v/greater_than_equal",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mFellow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHassan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maddresses\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user47\\Documents\\FastApi\\backend\\Lib\\site-packages\\pydantic\\main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Fellow\nscore\n  Input should be greater than or equal to 0 [type=greater_than_equal, input_value=-40, input_type=int]\n    For further information visit https://errors.pydantic.dev/2.12/v/greater_than_equal"
     ]
    }
   ],
   "source": [
    "Fellow(name = \"Hassan\", score= -40, addresses = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1439d78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fellow(name='Hassan', score=80, addresses=[])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fellow(name = \"Hassan\", score = 80, addresses = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9c39a83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Person\nname\n  Value error, Name must raise with a capital letter [type=value_error, input_value='solomon', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mName must raise with a capital letter\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m v\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mPerson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msolomon\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user47\\Documents\\FastApi\\backend\\Lib\\site-packages\\pydantic\\main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Person\nname\n  Value error, Name must raise with a capital letter [type=value_error, input_value='solomon', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/value_error"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int = Field(..., ge = 0)\n",
    "\n",
    "    @field_validator(\"name\")\n",
    "    def name_must_start_with_capital(cls, v):\n",
    "        if not v[0].isupper():\n",
    "            raise ValueError(\"Name must raise with a capital letter\")\n",
    "        return v\n",
    "    \n",
    "Person(name = \"solomon\", age = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2ef5b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Solomon', age=20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Person(name = \"Solomon\", age = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "566f21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from decimal import Decimal\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6638f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductReview(BaseModel):\n",
    "\n",
    "    review_id: int = Field(..., gt = 0, lt = 10000)\n",
    "    username"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
